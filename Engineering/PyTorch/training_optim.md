# Optimize Training Performance in PyTorch

This tutorial shows how to optimize training performance in PyTorch.

MFU (Model FLOPs Utilization) is a key metric to measure how efficiently a model utilizes the available computational resources during training. Higher MFU indicates better utilization of the hardware, leading to faster training times and improved performance.

